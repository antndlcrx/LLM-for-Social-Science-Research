{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRoL5Wa2aNN+gAtZ+DppFs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "from typing import List, Dict, Tuple, Any"
      ],
      "metadata": {
        "id": "oKkz-mmOUziZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/antndlcrx/LLM-for-Social-Science-Research.git"
      ],
      "metadata": {
        "id": "B5Xe7Hxe61Oc",
        "outputId": "f073e499-945b-463b-ce8d-e0fd84392648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLM-for-Social-Science-Research'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 76 (delta 31), reused 53 (delta 19), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (76/76), 76.09 KiB | 10.87 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory = 'LLM-for-Social-Science-Research/mappings'\n",
        "\n",
        "survey_mappings = {}\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.json'):\n",
        "        section_name = os.path.splitext(filename)[0]\n",
        "\n",
        "        with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
        "            survey_mappings[section_name] = json.load(file)\n",
        "\n",
        "\n",
        "ess = pd.read_csv('ESS10.csv')"
      ],
      "metadata": {
        "id": "aRBbbp8RV22-",
        "outputId": "d5a08493-adcc-4917-d58b-ebc58f6dd1e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-5fae74428a89>:13: DtypeWarning: Columns (166,172,174,607,608) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  ess = pd.read_csv('ESS10.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "survey_mappings.items()"
      ],
      "metadata": {
        "id": "sHzjO78EIrCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SurveyProfileGenerator:\n",
        "    def __init__(self,\n",
        "                 data: pd.DataFrame,\n",
        "                 respondent_id: str,\n",
        "                 survey_mappings: Dict[str, Dict[str, Any]],\n",
        "                 max_sections: int = 3,\n",
        "                 max_features: int = 3,\n",
        "                 fixed_features: List[str] = None):\n",
        "        \"\"\"\n",
        "        Initializes the SurveyProfileGenerator with survey mappings, maximum number of features per section,\n",
        "        and any fixed features that should always be included in the profiles.\n",
        "\n",
        "        Parameters:\n",
        "        - data (pd.DataFrame): The survey dataset.\n",
        "        - respondent_id (str): The column name for respondent IDs.\n",
        "        - survey_mappings (dict): Nested dictionary mapping of survey questions.\n",
        "        - max_sections (int): Maximum number of sections to randomly select.\n",
        "        - max_features (int): Maximum number of features to randomly select per section.\n",
        "        - fixed_features (List[str]): List of feature names that are fixed and always included.\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.respondent_id = respondent_id\n",
        "        self.survey_mappings = survey_mappings\n",
        "        self.max_sections = max_sections\n",
        "        self.max_features = max_features\n",
        "        self.fixed_features = fixed_features or []\n",
        "\n",
        "        # Build a mapping from feature names to their sections\n",
        "        self.feature_to_section = {\n",
        "            feature: section\n",
        "            for section, features in self.survey_mappings.items()\n",
        "            for feature in features\n",
        "        }\n",
        "\n",
        "    def create_random_profile(self, respondent: pd.Series) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Creates a random profile for a single respondent.\n",
        "\n",
        "        Parameters:\n",
        "        - respondent (pd.Series): A row from the DataFrame representing a respondent.\n",
        "\n",
        "        Returns:\n",
        "        - profile (dict): A dictionary representing the respondent's profile.\n",
        "        \"\"\"\n",
        "        profile = {'respondent_id': respondent[self.respondent_id]}\n",
        "\n",
        "        # Add fixed features\n",
        "        predictor_features = []\n",
        "        for feature in self.fixed_features:\n",
        "            if feature in respondent:\n",
        "                profile[feature] = respondent[feature]\n",
        "                predictor_features.append(feature)\n",
        "\n",
        "        available_sections = list(self.survey_mappings.keys())\n",
        "\n",
        "        # Randomly select sections\n",
        "        num_sections_to_select = min(self.max_sections, len(available_sections))\n",
        "        random_sections = random.sample(available_sections, num_sections_to_select)\n",
        "\n",
        "        # Collect selected features\n",
        "        selected_features = []\n",
        "        for section in random_sections:\n",
        "            features_in_section = list(self.survey_mappings[section].keys())\n",
        "            num_features_to_select = min(self.max_features, len(features_in_section))\n",
        "            selected_in_section = random.sample(features_in_section, num_features_to_select)\n",
        "            selected_features.extend(selected_in_section)\n",
        "\n",
        "        # Remove any fixed features from selected features\n",
        "        selected_features = [f for f in selected_features if f not in self.fixed_features]\n",
        "\n",
        "        if not selected_features:\n",
        "            # If no features are left after removing fixed features\n",
        "            return profile\n",
        "\n",
        "        # Select one feature as the response feature\n",
        "        response_feature = random.choice(selected_features)\n",
        "        selected_features.remove(response_feature)\n",
        "\n",
        "        # Add predictor features\n",
        "        for feature in selected_features:\n",
        "            if feature in respondent:\n",
        "                profile[feature] = respondent[feature]\n",
        "                predictor_features.append(feature)\n",
        "\n",
        "        # Add the response feature\n",
        "        if response_feature in respondent:\n",
        "            profile['response_feature'] = respondent[response_feature]\n",
        "            profile['response_feature_name'] = response_feature\n",
        "\n",
        "        return profile\n",
        "\n",
        "    def generate_profiles(self, num_profiles_per_respondent: int) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Generates profiles for all respondents in the dataset.\n",
        "\n",
        "        Parameters:\n",
        "        - num_profiles_per_respondent (int): Number of profiles to generate per respondent.\n",
        "\n",
        "        Returns:\n",
        "        - profiles (List[dict]): A list of respondent profiles.\n",
        "        \"\"\"\n",
        "        profiles = []\n",
        "        for _, respondent in self.data.iterrows():\n",
        "            for _ in range(num_profiles_per_respondent):\n",
        "                profile = self.create_random_profile(respondent)\n",
        "                profiles.append(profile)\n",
        "        return profiles\n",
        "\n",
        "    def profile_to_text(self, profile: Dict[str, Any]) -> Tuple[str, str]:\n",
        "        \"\"\"\n",
        "        Converts a profile into text form, turning profile features into a text description\n",
        "        and the response feature into an answer to an interview question.\n",
        "\n",
        "        Parameters:\n",
        "        - profile (dict): A respondent's profile.\n",
        "\n",
        "        Returns:\n",
        "        - preamble (str): The text description of the respondent.\n",
        "        - response (str): The answer to the interview question.\n",
        "        \"\"\"\n",
        "        lines = []\n",
        "\n",
        "        # Extract the response feature name and value\n",
        "        response_feature_name = profile.get('response_feature_name')\n",
        "        response_feature_value = profile.get('response_feature')\n",
        "\n",
        "        # Iterate over predictor features\n",
        "        for feature, value in profile.items():\n",
        "            if feature in ['respondent_id', 'response_feature', 'response_feature_name']:\n",
        "                continue  # Skip non-feature fields\n",
        "\n",
        "            if pd.isnull(value):\n",
        "                continue  # Skip features with NaN values\n",
        "\n",
        "            section = self.feature_to_section.get(feature)\n",
        "            if not section:\n",
        "                continue  # Skip if section is not found\n",
        "\n",
        "            feature_mapping = self.survey_mappings.get(section, {}).get(feature)\n",
        "            if not feature_mapping:\n",
        "                continue  # Skip if feature mapping is not found\n",
        "\n",
        "            description = feature_mapping.get('description', feature)\n",
        "            values_mapping = feature_mapping.get('values', {})\n",
        "            value_text = values_mapping.get(str(value), str(value))\n",
        "\n",
        "            lines.append(f\"{description}: {value_text}\")\n",
        "\n",
        "        # Get the question and response for the response feature\n",
        "        if response_feature_name and response_feature_value is not None:\n",
        "            section = self.feature_to_section.get(response_feature_name)\n",
        "            if section:\n",
        "                feature_mapping = self.survey_mappings.get(section, {}).get(response_feature_name)\n",
        "                if feature_mapping:\n",
        "                    question = feature_mapping.get('question', f\"Please answer the following question about {response_feature_name}:\")\n",
        "                    values_mapping = feature_mapping.get('values', {})\n",
        "                    response_text = values_mapping.get(str(response_feature_value), str(response_feature_value))\n",
        "                else:\n",
        "                    question = f\"Please answer the following question about {response_feature_name}:\"\n",
        "                    response_text = str(response_feature_value)\n",
        "            else:\n",
        "                question = f\"Please answer the following question about {response_feature_name}:\"\n",
        "                response_text = str(response_feature_value)\n",
        "\n",
        "        else:\n",
        "            # If no response feature is available\n",
        "            response_text = \"\"\n",
        "\n",
        "        preamble = '\\n'.join(lines)\n",
        "        return preamble, question, response_text\n"
      ],
      "metadata": {
        "id": "jvVaHkOsFfMv"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prof_generator = SurveyProfileGenerator(ess[0:3], survey_mappings=survey_mappings,\n",
        "                                        respondent_id='idno', max_sections=3, max_features=3,\n",
        "                                        fixed_features=['cntry', 'gndr'])"
      ],
      "metadata": {
        "id": "9Cp92P1w9gaa"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profiles = prof_generator.generate_profiles(1)"
      ],
      "metadata": {
        "id": "_-JuwyG0Gyxy"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for profile in profiles:\n",
        "    preambule, question, response = prof_generator.profile_to_text(profile)\n",
        "    print(f\"Profile: {preambule}. \\n\\nQuestion: {question} \\n\\nResponse: {response}\")\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "NNeCUiXRLtyA",
        "outputId": "f79201a9-2be2-498d-a85d-9e45c36bfbc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profile: Country: Belgium\n",
            "Gender: Female\n",
            "Country of birth, mother: Nigeria\n",
            "Discrimination of respondent's group: religion: Not marked\n",
            "Discrimination of respondent's group: disability: Not marked\n",
            "In country government sticks to policies regardless of what most people think: Not applicable\n",
            "In country the will of the people cannot be stopped: 7\n",
            "Different political parties offer clear alternatives to one another: 8. \n",
            "\n",
            "Question: Which party did you vote for in that election? (Switzerland) \n",
            "\n",
            "Response: nan\n",
            "----------------------------------------\n",
            "Profile: Country: Belgium\n",
            "Gender: Female\n",
            "Boycotted certain products last 12 months: No\n",
            "Taken part in public demonstration last 12 months: No\n",
            "Posted or shared anything about politics online last 12 months: No\n",
            "Placement on left right scale: 5\n",
            "European Union: European unification go further or gone too far: 5\n",
            "Total contracted hours per week in main job, overtime excluded: 40\n",
            "Ever unemployed and seeking work for a period more than three months: No\n",
            "Household's total net income, all sources: Don't know. \n",
            "\n",
            "Question: On the whole how satisfied are you with the present state of the economy in [country]? \n",
            "\n",
            "Response: 5\n",
            "----------------------------------------\n",
            "Profile: Country: Belgium\n",
            "Gender: Male\n",
            "News about politics and current affairs, watching, reading or listening, in minutes: 150\n",
            "Confident in own ability to participate in politics: Quite confident\n",
            "Most people can be trusted or you can't be too careful: 6\n",
            "Important to get respect from others: Somewhat like me\n",
            "Important to be successful and that people recognise achievements: Somewhat like me. \n",
            "\n",
            "Question: I will briefly describe a person. Please tell me how much this person is or is not like you. She/he likes surprises and is always looking for new things to do. She/he thinks it is important to do lots of different things in life. \n",
            "\n",
            "Response: Very much like me\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next Steps"
      ],
      "metadata": {
        "id": "d_hfJsRwEXBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "Hun2Dl3-Qzuj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "gUprv-AfQ1Hg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "70m3Oi1JQ9EK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompts(profiles: Dict[str, Any]):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    prompt_main = \"Edit the text below to create a dialog. First part should prompt a model to take on a given personality from features given in the profile. Then, this model with the personality should be asked a question stated in the prompt. Then, the model should answer the qestion with the probided response.\"\n",
        "\n",
        "    prompts = []\n",
        "    for profile in profiles:\n",
        "        preamble, question, response = prof_generator.profile_to_text(profile)\n",
        "        prompt = f\"{prompt_main}\\n<<<Profile: {preamble}>>>. \\n<<<Question: {question}>>>. \\n<<<Response: {response}>>>\"\n",
        "        prompts.append(prompt)\n",
        "    return prompts"
      ],
      "metadata": {
        "id": "pGyaJG2lUCN7"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profiles[0]"
      ],
      "metadata": {
        "id": "g-Ex3oJteeZN",
        "outputId": "90c697ad-bce6-4772-ab81-79f0e718f824",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'respondent_id': 10038,\n",
              " 'cntry': 'BE',\n",
              " 'gndr': 2,\n",
              " 'mbrncntc': 'NG',\n",
              " 'dscrrlg': 0,\n",
              " 'dscrdsb': 0,\n",
              " 'stpldmc': 66,\n",
              " 'wpestopc': 7,\n",
              " 'dfprtal': 8,\n",
              " 'prtvtghu': nan,\n",
              " 'prtvtdgr': nan,\n",
              " 'response_feature': nan,\n",
              " 'response_feature_name': 'prtvthch'}"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = create_prompts(profiles)"
      ],
      "metadata": {
        "id": "r_N8ycb4G-2Y"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = [model.generate_content(prompt) for prompt in prompts]\n",
        "text_outputs = [output.text for output in outputs]"
      ],
      "metadata": {
        "id": "Tr4dHlCQGq55"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_outputs[1]"
      ],
      "metadata": {
        "id": "VRNxBU4LHnFV",
        "outputId": "b90eb94f-ed1e-48ed-e0d9-bda58bfb3bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"**You:** Okay, I'm going to introduce you to someone. Imagine you're a woman living in Belgium. You work full-time, and you're not particularly active in politics. You're pretty neutral on things like European unification. \\n\\n**Model (as Belgian woman):** Okay, I'm ready. \\n\\n**You:**  How satisfied are you with the current state of the economy in Belgium? \\n\\n**Model (as Belgian woman):** Hmm, I'd say I'm about a 5 out of 10 satisfied.  It's not great, but it's not terrible either. \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for profile in profiles:\n",
        "    preambule, question, response = prof_generator.profile_to_text(profile)\n",
        "    print(f\"Profile: {preambule}. \\n\\nQuestion: {question} \\n\\nResponse: {response}\")\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "vk05agqSlDmu",
        "outputId": "70a7847f-5c5d-4d68-81ed-a1f4cebc3a81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profile: Country: Belgium\n",
            "Gender: Female\n",
            "Country of birth, mother: Nigeria\n",
            "Discrimination of respondent's group: religion: Not marked\n",
            "Discrimination of respondent's group: disability: Not marked\n",
            "In country government sticks to policies regardless of what most people think: Not applicable\n",
            "In country the will of the people cannot be stopped: 7\n",
            "Different political parties offer clear alternatives to one another: 8. \n",
            "\n",
            "Question: Which party did you vote for in that election? (Switzerland) \n",
            "\n",
            "Response: nan\n",
            "----------------------------------------\n",
            "Profile: Country: Belgium\n",
            "Gender: Female\n",
            "Boycotted certain products last 12 months: No\n",
            "Taken part in public demonstration last 12 months: No\n",
            "Posted or shared anything about politics online last 12 months: No\n",
            "Placement on left right scale: 5\n",
            "European Union: European unification go further or gone too far: 5\n",
            "Total contracted hours per week in main job, overtime excluded: 40\n",
            "Ever unemployed and seeking work for a period more than three months: No\n",
            "Household's total net income, all sources: Don't know. \n",
            "\n",
            "Question: On the whole how satisfied are you with the present state of the economy in [country]? \n",
            "\n",
            "Response: 5\n",
            "----------------------------------------\n",
            "Profile: Country: Belgium\n",
            "Gender: Male\n",
            "News about politics and current affairs, watching, reading or listening, in minutes: 150\n",
            "Confident in own ability to participate in politics: Quite confident\n",
            "Most people can be trusted or you can't be too careful: 6\n",
            "Important to get respect from others: Somewhat like me\n",
            "Important to be successful and that people recognise achievements: Somewhat like me. \n",
            "\n",
            "Question: I will briefly describe a person. Please tell me how much this person is or is not like you. She/he likes surprises and is always looking for new things to do. She/he thinks it is important to do lots of different things in life. \n",
            "\n",
            "Response: Very much like me\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "profiles[1]"
      ],
      "metadata": {
        "id": "2feC1d6RIMqq",
        "outputId": "a556698a-eea8-4976-8085-d6973b7184bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'respondent_id': 10053,\n",
              " 'cntry': 'BE',\n",
              " 'gndr': 2,\n",
              " 'bctprd': 2,\n",
              " 'pbldmna': 2,\n",
              " 'pstplonl': 2,\n",
              " 'lrscale': 5,\n",
              " 'euftf': 5,\n",
              " 'wkhct': 40,\n",
              " 'uemp3m': 2,\n",
              " 'hinctnta': 88,\n",
              " 'response_feature': 5,\n",
              " 'response_feature_name': 'stfeco'}"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dealing with bad Mappings\n",
        "\n",
        "def find_numeric_to_numeric_mappings(survey_mappings: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Identifies mappings with numeric-to-numeric key-value pairs in the nested survey_mappings dictionary.\n",
        "    Returns a dictionary with the section and feature names for each problematic mapping.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    survey_mappings : dict\n",
        "        The nested dictionary containing sections and features of survey mappings.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        A dictionary where each key is a section name and each value is a list of features that contain\n",
        "        numeric-to-numeric mappings in their \"values\" field.\n",
        "    \"\"\"\n",
        "\n",
        "    problematic_mappings = {}\n",
        "\n",
        "    for section, features in survey_mappings.items():\n",
        "        for feature, feature_data in features.items():\n",
        "            # Check if \"values\" key exists in feature data\n",
        "            if \"values\" in feature_data:\n",
        "                # Flag to indicate if this feature has numeric-to-numeric mappings\n",
        "                has_numeric_to_numeric = False\n",
        "\n",
        "                for key, value in feature_data[\"values\"].items():\n",
        "                    # Check if both key and value are numeric (integer-like or string numeric)\n",
        "                    if key.isdigit() and (value.isdigit() or isinstance(value, int)):\n",
        "                        has_numeric_to_numeric = True\n",
        "                        break\n",
        "\n",
        "                if has_numeric_to_numeric:\n",
        "                    if section not in problematic_mappings:\n",
        "                        problematic_mappings[section] = []\n",
        "                    problematic_mappings[section].append(feature)\n",
        "\n",
        "    return problematic_mappings\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "08tj3IDoJfD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problematic_mappings = find_numeric_to_numeric_mappings(survey_mappings)\n",
        "problematic_mappings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i11QqOztJmE1",
        "outputId": "f1cbff55-1419-48c2-891c-fcfa75c56dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'relationship_parents_and_at_work': ['stfmjob',\n",
              "  'mansupp',\n",
              "  'teamfeel',\n",
              "  'wrkextra'],\n",
              " 'political_opinions': ['lrscale',\n",
              "  'stflife',\n",
              "  'stfeco',\n",
              "  'stfgov',\n",
              "  'stfdem',\n",
              "  'stfedu',\n",
              "  'stfhlth',\n",
              "  'euftf',\n",
              "  'imbgeco',\n",
              "  'imueclt',\n",
              "  'imwbcnt'],\n",
              " 'internet_use_social_trust': ['ppltrst',\n",
              "  'pplfair',\n",
              "  'pplhlp',\n",
              "  'trstprl',\n",
              "  'trstlgl',\n",
              "  'trstplc',\n",
              "  'trstplt',\n",
              "  'trstprt',\n",
              "  'trstep',\n",
              "  'trstun',\n",
              "  'trstsci'],\n",
              " 'well_being_emot_attachment': ['happy', 'inprdsc', 'atchctr', 'atcherp'],\n",
              " 'religion': ['rlgrl'],\n",
              " 'climate_change_eu': ['ccrdprs', 'testic34', 'testic35', 'testic36'],\n",
              " 'understanding_democracy': ['fairelc',\n",
              "  'dfprtal',\n",
              "  'medcrgv',\n",
              "  'rghmgpr',\n",
              "  'votedir',\n",
              "  'cttresa',\n",
              "  'gptpel',\n",
              "  'gvctzpv',\n",
              "  'grdfinc',\n",
              "  'viepol',\n",
              "  'wpestop',\n",
              "  'keydec',\n",
              "  'fairelcc',\n",
              "  'dfprtalc',\n",
              "  'medcrgvc',\n",
              "  'rghmgprc',\n",
              "  'votedirc',\n",
              "  'cttresac',\n",
              "  'gptpelcc',\n",
              "  'gvctzpvc',\n",
              "  'grdfincc',\n",
              "  'viepolc',\n",
              "  'wpestopc',\n",
              "  'keydecc',\n",
              "  'chpldmi',\n",
              "  'chpldmc',\n",
              "  'stpldmi',\n",
              "  'stpldmc',\n",
              "  'accalaw']}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LzlhQdiM5ON",
        "outputId": "e39229e0-1fcb-47fe-f0b8-091b8e746a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ess['rlgdnbsk'].value_counts()"
      ],
      "metadata": {
        "id": "mKshPCO6QghH",
        "outputId": "4753e3ac-5edf-4edb-8e5b-40f978e8a2bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rlgdnbsk\n",
              "9.0       703\n",
              "6666.0    340\n",
              "1.0       138\n",
              "2.0       100\n",
              "4.0        80\n",
              "9999.0     21\n",
              "3.0        17\n",
              "10.0        5\n",
              "7777.0      4\n",
              "14.0        4\n",
              "7.0         2\n",
              "8.0         2\n",
              "12.0        1\n",
              "6.0         1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rlgdnbsk</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9.0</th>\n",
              "      <td>703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6666.0</th>\n",
              "      <td>340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999.0</th>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.0</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7777.0</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14.0</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.0</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.0</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ess['rlgdeme'].value_counts()"
      ],
      "metadata": {
        "id": "ZGpElzROP6Zg",
        "outputId": "36968887-d1ec-4de2-9ac4-c51b1bf470ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rlgdeme\n",
              "6666.0    1261\n",
              "8.0          6\n",
              "5.0          6\n",
              "3.0          3\n",
              "1.0          1\n",
              "4.0          1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rlgdeme</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6666.0</th>\n",
              "      <td>1261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.0</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5.0</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    }
  ]
}